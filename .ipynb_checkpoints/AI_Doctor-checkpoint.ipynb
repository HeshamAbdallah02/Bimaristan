{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeshamAbdallah02/Bimaristan/blob/master/AI_Doctor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5tKn3fazeMT",
        "outputId": "8ab72830-b9d2-4c97-b02a-e1b2dadf2ee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: iterative-stratification in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (0.1.9)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (0.13.0)\n",
            "Requirement already satisfied: xgboost in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (3.0.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from iterative-stratification) (2.2.6)\n",
            "Requirement already satisfied: scipy in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from iterative-stratification) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from imbalanced-learn) (0.1.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install iterative-stratification scikit-learn imbalanced-learn xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPFnnBSyxve7"
      },
      "source": [
        "# **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H3wFYsB5rPDb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import (\n",
        "    OneHotEncoder, StandardScaler, OrdinalEncoder,\n",
        "    MultiLabelBinarizer, FunctionTransformer\n",
        ")\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkHNhMvT--L2"
      },
      "source": [
        "# Custom XGBoost classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ahTxQXhP-_2u"
      },
      "outputs": [],
      "source": [
        "class DynamicXGBClassifier(XGBClassifier):\n",
        "    def fit(self, X, y, **kwargs):\n",
        "        if self.objective == 'multi:softprob':\n",
        "            self.set_params(num_class=len(np.unique(y)))\n",
        "        return super().fit(X, y, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFxgOny4x-iK"
      },
      "source": [
        "# **1. Load and prepare the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4nsJUytvx_XS"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('disease_diagnosis.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUSdQl3VzJDp"
      },
      "source": [
        "# **2. Preprocess the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkitPjGr0MB4"
      },
      "source": [
        "Function to process blood pressure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7NL8uaFZ0Nfo"
      },
      "outputs": [],
      "source": [
        "def process_blood_pressure(bp_string):\n",
        "    try:\n",
        "        systolic, diastolic = map(int, bp_string.split('/'))\n",
        "        return systolic, diastolic\n",
        "    except:\n",
        "        return np.nan, np.nan\n",
        "\n",
        "def combine_symptoms(row):\n",
        "    return [str(symptom) for symptom in row[['Symptom_1', 'Symptom_2', 'Symptom_3']]\n",
        "            if pd.notnull(symptom)]\n",
        "\n",
        "df['Systolic'], df['Diastolic'] = zip(*df['Blood_Pressure_mmHg'].apply(process_blood_pressure))\n",
        "df['Symptoms'] = df.apply(combine_symptoms, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DsvQsqWvYT5"
      },
      "source": [
        "Feature engineering: clinical indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CFVD6ReWvcNC"
      },
      "outputs": [],
      "source": [
        "df['Has_Fever'] = (df['Body_Temperature_C'] >= 38).astype(int)\n",
        "df['Tachycardia'] = (df['Heart_Rate_bpm'] > 100).astype(int)\n",
        "df['Hypertension_Stage'] = pd.cut(df['Systolic'],\n",
        "                                 bins=[0, 120, 130, 140, 180],\n",
        "                                 labels=['Normal', 'Elevated', 'Stage1', 'Stage2'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz90era7vjJb"
      },
      "source": [
        "#**3. Define preprocessing pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ordIW4Huvp3y"
      },
      "outputs": [],
      "source": [
        "class SafeMultiLabelBinarizer(MultiLabelBinarizer):\n",
        "    def fit_transform(self, X, y=None):\n",
        "        return super().fit_transform(X)\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return super().transform(X)\n",
        "\n",
        "symptom_transformer = Pipeline([\n",
        "    ('extractor', FunctionTransformer(lambda x: np.array(x.tolist()), validate=False)),\n",
        "    ('encoder', SafeMultiLabelBinarizer())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), ['Age', 'Heart_Rate_bpm', 'Body_Temperature_C',\n",
        "                                  'Oxygen_Saturation_%', 'Systolic', 'Diastolic']),\n",
        "        ('symp', symptom_transformer, 'Symptoms'),\n",
        "        ('clin', OneHotEncoder(handle_unknown='ignore'), ['Gender', 'Hypertension_Stage']),\n",
        "        ('ind', 'passthrough', ['Has_Fever', 'Tachycardia'])\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pijo_3Fhv43b"
      },
      "source": [
        "# **4. Define multi-output model with class weights**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SYHFWD4cD5Wg"
      },
      "outputs": [],
      "source": [
        "from sklearn.multioutput import MultiOutputClassifier as _MOC\n",
        "\n",
        "class SafeMultiOutputClassifier(_MOC):\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        For each underlying estimator:\n",
        "          - call its predict(X)\n",
        "          - if it returns a 2D array, collapse via argmax → 1D labels\n",
        "          - otherwise keep it as-is\n",
        "        Then stack all 1D arrays column-wise.\n",
        "        \"\"\"\n",
        "        cols = []\n",
        "        for est in self.estimators_:\n",
        "            p = est.predict(X)\n",
        "            # if you got back something like (n_samples, n_classes), pick the highest-prob class\n",
        "            if hasattr(p, 'ndim') and p.ndim > 1:\n",
        "                p = np.argmax(p, axis=1)\n",
        "            cols.append(p)\n",
        "        # now each p is (n_samples,) — stack into (n_samples, n_outputs)\n",
        "        return np.stack(cols, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BTcjHhY0v7pD"
      },
      "outputs": [],
      "source": [
        "base_model = DynamicXGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    tree_method='hist',\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "model = SafeMultiOutputClassifier(\n",
        "    Pipeline([\n",
        "       ('preprocessor', preprocessor),\n",
        "       ('imputer',     KNNImputer(n_neighbors=5)),\n",
        "       ('classifier',  DynamicXGBClassifier(\n",
        "                          objective='multi:softprob',\n",
        "                          tree_method='hist',\n",
        "                          use_label_encoder=False\n",
        "                       ))\n",
        "    ]),\n",
        "    n_jobs=-1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaF1bhua1cdI"
      },
      "source": [
        "# **5. Prepare targets & features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GfM4UB2O1emf"
      },
      "outputs": [],
      "source": [
        "X = df[['Age', 'Gender', 'Symptoms', 'Heart_Rate_bpm', 'Body_Temperature_C',\n",
        "        'Oxygen_Saturation_%', 'Systolic', 'Diastolic', 'Has_Fever',\n",
        "        'Tachycardia', 'Hypertension_Stage']]\n",
        "\n",
        "diagnosis_encoder = OneHotEncoder(sparse_output=False)\n",
        "severity_encoder = OrdinalEncoder(categories=[['Mild', 'Moderate', 'Severe']])\n",
        "treatment_encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "y = np.hstack([\n",
        "    diagnosis_encoder.fit_transform(df[['Diagnosis']]),\n",
        "    severity_encoder.fit_transform(df[['Severity']]),\n",
        "    treatment_encoder.fit_transform(df[['Treatment_Plan']])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmp2ylO71gu3"
      },
      "source": [
        "# **6. Train-test split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5l85iTFZ1mca"
      },
      "outputs": [],
      "source": [
        "# First split: hold-out vs “the rest”\n",
        "X_rest, X_holdout, y_rest, y_holdout = train_test_split(\n",
        "    X, y, test_size=0.15, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Then split X_rest into your train/test for CV/tuning\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_rest, y_rest, test_size=0.20, random_state=42, stratify=y_rest\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siQVZIkpCpe4",
        "outputId": "53b964a5-39d9-4a7a-c488-c3b66b0247c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✔️ model.fit completed without error.\n",
            "Estimator # 0 predict OK: shape = (340, 2), dtype = float64\n",
            "Estimator # 1 predict OK: shape = (340, 2), dtype = float64\n",
            "Estimator # 2 predict OK: shape = (340, 2), dtype = float64\n",
            "Estimator # 3 predict OK: shape = (340, 2), dtype = float64\n",
            "Estimator # 4 predict OK: shape = (340, 2), dtype = float64\n",
            "Estimator # 5 predict OK: shape = (340,), dtype = int64\n",
            "Estimator # 6 predict OK: shape = (340, 2), dtype = float64\n",
            "Estimator # 7 predict OK: shape = (340, 2), dtype = float64\n",
            "Estimator # 8 predict OK: shape = (340, 2), dtype = float64\n",
            "Combined predict OK: (340, 9)\n"
          ]
        }
      ],
      "source": [
        "# --- DEBUG CELL: which estimator is throwing the inhomogeneous‐shape error? ---\n",
        "\n",
        "# Fit your multi‐output model on the training split\n",
        "model.fit(X_train, y_train)\n",
        "print(\"✔️ model.fit completed without error.\")\n",
        "\n",
        "# Try each sub‐estimator’s predict in isolation\n",
        "for idx, est in enumerate(model.estimators_):\n",
        "    try:\n",
        "        preds = est.predict(X_test)\n",
        "        print(f\"Estimator #{idx:>2} predict OK: shape = {preds.shape}, dtype = {preds.dtype}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Estimator #{idx:>2} predict FAILED:\", e)\n",
        "\n",
        "# Finally, test the combined predict\n",
        "try:\n",
        "    all_preds = model.predict(X_test)\n",
        "    print(\"Combined predict OK:\", all_preds.shape)\n",
        "except Exception as e:\n",
        "    print(\"Combined model.predict FAILED:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlfWxE_f1qsX"
      },
      "source": [
        "# **7. Custom scoring function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "tTvor_4-1ufQ"
      },
      "outputs": [],
      "source": [
        "def multi_output_macro_f1(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute per-output macro-F1 and average them,\n",
        "    but treat any nan F1 as 0.0 so the overall score stays numeric.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    for i in range(y_true.shape[1]):\n",
        "        score_i = f1_score(\n",
        "            y_true[:, i],\n",
        "            y_pred[:, i],\n",
        "            average='macro',\n",
        "            zero_division=0\n",
        "        )\n",
        "        # convert any nan result into 0.0\n",
        "        if np.isnan(score_i):\n",
        "            score_i = 0.0\n",
        "        scores.append(score_i)\n",
        "    return float(np.mean(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwMDHGvF7tPY",
        "outputId": "0f0ecc97-cae6-4ae6-b025-27c111e1b94c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity test (should be a number, not nan): 1.0\n"
          ]
        }
      ],
      "source": [
        "# Quick sanity check: this should print a finite float (e.g. 1.0 if you pass perfect data)\n",
        "print(\"Sanity test (should be a number, not nan):\",\n",
        "      multi_output_macro_f1(y_train[:20], y_train[:20]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0Op04qdBm7J",
        "outputId": "e65e5b4a-7021-4f3c-c057-84d0b50edf24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline 3-fold CV macro-F1: 0.9987 ± 0.0018\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# 1. Reuse the same CV splitter and scorer\n",
        "cv = MultilabelStratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "f1_scorer = make_scorer(multi_output_macro_f1)\n",
        "\n",
        "# 2. Evaluate your base model without any grid search\n",
        "baseline_scores = cross_val_score(\n",
        "    model,           # your MultiOutputClassifier pipeline\n",
        "    X_train,         # training inputs\n",
        "    y_train,         # training labels\n",
        "    cv=cv,\n",
        "    scoring=f1_scorer,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(f\"Baseline 3-fold CV macro-F1: {baseline_scores.mean():.4f} ± {baseline_scores.std():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLjKnTBp0Row"
      },
      "source": [
        "# **8. Hyperparameter tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SCIwehkj0QKQ"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'estimator__classifier__max_depth': [4, 6],\n",
        "    'estimator__classifier__learning_rate': [0.05, 0.1],\n",
        "    'estimator__classifier__n_estimators': [200, 300]\n",
        "}\n",
        "\n",
        "# 1. Wrap your multi-output F1 in a proper scorer\n",
        "f1_scorer = make_scorer(multi_output_macro_f1)\n",
        "\n",
        "# 2. Create a shuffled, reproducible stratified splitter\n",
        "cv = MultilabelStratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "# 3. Plug into GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator   = model,        # your MultiOutputClassifier pipeline\n",
        "    param_grid  = param_grid,   # same dict you already defined\n",
        "    cv          = cv,\n",
        "    scoring     = f1_scorer,\n",
        "    verbose     = 3,\n",
        "    error_score = 'raise',\n",
        "    n_jobs      = -1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2IobKMcV9Jm",
        "outputId": "54999e35-b8f8-4c01-e1db-9a8e9017c454"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nested CV F1: 1.0000 ± 0.0000\n"
          ]
        }
      ],
      "source": [
        "outer_cv = MultilabelStratifiedKFold(\n",
        "    n_splits=5, shuffle=True, random_state=0\n",
        ")\n",
        "\n",
        "nested_scores = cross_val_score(\n",
        "    grid_search,       # your entire GridSearchCV pipeline\n",
        "    X_rest, y_rest,    # the “rest” (not the hold-out)\n",
        "    cv=outer_cv,\n",
        "    scoring=make_scorer(multi_output_macro_f1),\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"Nested CV F1: %.4f ± %.4f\"\n",
        "      % (nested_scores.mean(), nested_scores.std()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t6oSPoM16sK"
      },
      "source": [
        "# **9. Training**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFTsIqHI1-74",
        "outputId": "6d4915ac-942e-4da9-be3a-2a5330853a8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Mean test scores per setting:\n",
            "[0.99902732 0.99886171 0.99869671 0.9985305  0.99886171 0.99886171\n",
            " 0.9985305  0.9985305 ]\n",
            "Best params: {'estimator__classifier__learning_rate': 0.05, 'estimator__classifier__max_depth': 4, 'estimator__classifier__n_estimators': 200}\n",
            "Best CV macro-F1: 0.9990273167706358\n"
          ]
        }
      ],
      "source": [
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Mean test scores per setting:\")\n",
        "print(grid_search.cv_results_['mean_test_score'])\n",
        "\n",
        "print(\"Best params:\", grid_search.best_params_)\n",
        "print(\"Best CV macro-F1:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKfKtM2L7CYm"
      },
      "source": [
        "# **10. Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKo57Dfq7KIG",
        "outputId": "20893ea7-8e38-49c2-8842-04a0ba014085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Diagnosis ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Bronchitis       1.00      1.00      1.00        57\n",
            "        Cold       1.00      1.00      1.00        28\n",
            "         Flu       1.00      1.00      1.00        50\n",
            "     Healthy       1.00      1.00      1.00       198\n",
            "   Pneumonia       1.00      1.00      1.00         7\n",
            "\n",
            "   micro avg       1.00      1.00      1.00       340\n",
            "   macro avg       1.00      1.00      1.00       340\n",
            "weighted avg       1.00      1.00      1.00       340\n",
            " samples avg       1.00      1.00      1.00       340\n",
            "\n",
            "=== Severity ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Mild       1.00      1.00      1.00       226\n",
            "    Moderate       1.00      1.00      1.00        50\n",
            "      Severe       1.00      1.00      1.00        64\n",
            "\n",
            "    accuracy                           1.00       340\n",
            "   macro avg       1.00      1.00      1.00       340\n",
            "weighted avg       1.00      1.00      1.00       340\n",
            "\n",
            "=== Treatment Plan ===\n",
            "                                precision    recall  f1-score   support\n",
            "\n",
            "Hospitalization and medication       1.00      1.00      1.00        64\n",
            "           Medication and rest       1.00      1.00      1.00        50\n",
            "               Rest and fluids       1.00      1.00      1.00       226\n",
            "\n",
            "                     micro avg       1.00      1.00      1.00       340\n",
            "                     macro avg       1.00      1.00      1.00       340\n",
            "                  weighted avg       1.00      1.00      1.00       340\n",
            "                   samples avg       1.00      1.00      1.00       340\n",
            "\n",
            "Overall multi-output macro-F1: 1.0000\n",
            "Predicted diagnosis: Bronchitis\n",
            "Predicted severity: Severe\n",
            "Recommended treatment plan: ['Hospitalization and medication']\n"
          ]
        }
      ],
      "source": [
        "# Retrieve best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on test set using SafeMultiOutputClassifier\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Define output slice sizes\n",
        "n_diag  = diagnosis_encoder.categories_[0].shape[0]\n",
        "n_sev   = 1\n",
        "n_treat = treatment_encoder.categories_[0].shape[0]\n",
        "\n",
        "# Print classification reports\n",
        "print(\"=== Diagnosis ===\")\n",
        "print(classification_report(\n",
        "    y_test[:, :n_diag],\n",
        "    y_pred[:, :n_diag],\n",
        "    target_names=diagnosis_encoder.categories_[0],\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "print(\"=== Severity ===\")\n",
        "print(classification_report(\n",
        "    y_test[:, n_diag:n_diag+n_sev].ravel(),\n",
        "    y_pred[:, n_diag:n_diag+n_sev].ravel(),\n",
        "    target_names=severity_encoder.categories_[0].tolist(),\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "print(\"=== Treatment Plan ===\")\n",
        "print(classification_report(\n",
        "    y_test[:, -n_treat:],\n",
        "    y_pred[:, -n_treat:],\n",
        "    target_names=treatment_encoder.categories_[0],\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "# Overall multi-output macro-F1\n",
        "print(f\"Overall multi-output macro-F1: {multi_output_macro_f1(y_test, y_pred):.4f}\")\n",
        "\n",
        "\n",
        "# **12. Function to make predictions for new patients**\n",
        "\n",
        "def predict_patient(record: dict):\n",
        "    \"\"\"\n",
        "    record should contain keys:\n",
        "      'Age', 'Gender', 'Symptoms', 'Heart_Rate_bpm',\n",
        "      'Body_Temperature_C', 'Oxygen_Saturation_%',\n",
        "      'Blood_Pressure_mmHg' (e.g. \"120/80\")\n",
        "    Returns a dict with Diagnosis, Severity, Treatment_Plan.\n",
        "    \"\"\"\n",
        "    dfp = pd.DataFrame([record])\n",
        "    dfp[['Systolic','Diastolic']] = dfp['Blood_Pressure_mmHg'].apply(\n",
        "        lambda s: pd.Series(process_blood_pressure(s))\n",
        "    )\n",
        "    dfp['Has_Fever']    = (dfp['Body_Temperature_C'] >= 38).astype(int)\n",
        "    dfp['Tachycardia']  = (dfp['Heart_Rate_bpm'] > 100).astype(int)\n",
        "    dfp['Hypertension_Stage'] = pd.cut(\n",
        "        dfp['Systolic'],\n",
        "        bins=[0,120,130,140,180],\n",
        "        labels=['Normal','Elevated','Stage1','Stage2']\n",
        "    )\n",
        "    dfp['Symptoms'] = dfp['Symptoms']\n",
        "    Xp = dfp[['Age','Gender','Symptoms','Heart_Rate_bpm',\n",
        "              'Body_Temperature_C','Oxygen_Saturation_%',\n",
        "              'Systolic','Diastolic','Has_Fever','Tachycardia',\n",
        "              'Hypertension_Stage']]\n",
        "    y_p = best_model.predict(Xp)\n",
        "    diag_pred = diagnosis_encoder.inverse_transform(y_p[:, :n_diag])\n",
        "    sev_pred  = severity_encoder.inverse_transform(y_p[:, n_diag:n_diag+n_sev])\n",
        "    treat_pred= treatment_encoder.inverse_transform(y_p[:, -n_treat:])\n",
        "    return {\n",
        "        'Diagnosis': diag_pred[0] if len(diag_pred[0])>1 else diag_pred[0][0],\n",
        "        'Severity': sev_pred[0][0],\n",
        "        'Treatment_Plan': list(treat_pred[0])\n",
        "    }\n",
        "\n",
        "\n",
        "# **Example usage:**\n",
        "\n",
        "new_patient = {\n",
        "    'Age': 52,\n",
        "    'Gender': 'Female',\n",
        "    'Symptoms': ['Cough','Fatigue'],\n",
        "    'Heart_Rate_bpm': 88,\n",
        "    'Body_Temperature_C': 38.5,\n",
        "    'Oxygen_Saturation_%': 94,\n",
        "    'Blood_Pressure_mmHg': '135/85'\n",
        "}\n",
        "\n",
        "result = predict_patient(new_patient)\n",
        "print(\"Predicted diagnosis:\", result['Diagnosis'])\n",
        "print(\"Predicted severity:\", result['Severity'])\n",
        "print(\"Recommended treatment plan:\", result['Treatment_Plan'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13dZplwapDhX",
        "outputId": "d4d346c4-392a-41bd-88f4-5cf894f5f6ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jittered F1: 0.9712985141868954\n"
          ]
        }
      ],
      "source": [
        "def perturb(X, sigma=0.01):\n",
        "    Xp = X.copy()\n",
        "    # Add Gaussian noise: 1% stddev\n",
        "    for col in ['Body_Temperature_C','Heart_Rate_bpm','Systolic','Diastolic']:\n",
        "        Xp[col] += np.random.normal(0, sigma * Xp[col].mean(), size=Xp.shape[0])\n",
        "    return Xp\n",
        "\n",
        "Xjitter = perturb(pd.DataFrame(X_test, columns=X.columns))\n",
        "yj_pred = best_model.predict(Xjitter)\n",
        "print(\"Jittered F1:\", multi_output_macro_f1(y_test, yj_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbDnHz9Dqj8p",
        "outputId": "85110b5b-cfad-401b-b5d9-21d79c7df027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: shap in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (0.47.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from shap) (2.2.6)\n",
            "Requirement already satisfied: scipy in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from shap) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from shap) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from shap) (0.61.2)\n",
            "Requirement already satisfied: cloudpickle in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from shap) (4.13.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from numba>=0.54->shap) (0.44.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn->shap) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn->shap) (3.6.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install shap\n",
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "mtPlemiM_i5q",
        "outputId": "b2133cfd-54aa-4822-d61b-0eebeeb11ce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: matplotlib in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\20109\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "matplotlib is not installed so plotting is not available! Run `pip install matplotlib` to fix this.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m explainer = shap.TreeExplainer(xgb_model)\n\u001b[32m     12\u001b[39m shap_values = explainer.shap_values(X_test_transformed)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mshap\u001b[49m\u001b[43m.\u001b[49m\u001b[43msummary_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdot\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\shap\\__init__.py:32\u001b[39m, in \u001b[36munsupported\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munsupported\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(_no_matplotlib_warning)\n",
            "\u001b[31mImportError\u001b[39m: matplotlib is not installed so plotting is not available! Run `pip install matplotlib` to fix this."
          ]
        }
      ],
      "source": [
        "%pip install matplotlib\n",
        "single_model = best_model.estimators_[0]\n",
        "xgb_model = single_model.named_steps['classifier']\n",
        "X_test_transformed = single_model.named_steps['preprocessor'].transform(X_test)\n",
        "\n",
        "try:\n",
        "    feature_names = single_model.named_steps['preprocessor'].get_feature_names_out()\n",
        "except:\n",
        "    feature_names = [f'Feature {i}' for i in range(X_test_transformed.shape[1])]\n",
        "\n",
        "explainer = shap.TreeExplainer(xgb_model)\n",
        "shap_values = explainer.shap_values(X_test_transformed)\n",
        "\n",
        "shap.summary_plot(shap_values, X_test_transformed, feature_names=feature_names, plot_type=\"dot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUtn5m9mSz_D",
        "outputId": "db9c31e9-e7bc-4f23-edd1-e68aaba81720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hold-out F1: 0.9934253234427809\n"
          ]
        }
      ],
      "source": [
        "# Evaluate your final model on the true hold-out set:\n",
        "yh_pred = best_model.predict(X_holdout)\n",
        "print(\"Hold-out F1:\",\n",
        "      multi_output_macro_f1(y_holdout, yh_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj2b7EWA2ECI"
      },
      "source": [
        "# **11. Function to make predictions for new patients**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x19icBsX2KXA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V_wV6862MEQ"
      },
      "source": [
        "# **Example usage:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG2epm7D2haH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOJQ2bDdNRDL9T8QGM8ubuE",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
